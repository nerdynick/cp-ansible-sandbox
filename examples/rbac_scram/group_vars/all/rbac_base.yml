control_center_kafka_listener_name: internal
schema_registry_kafka_listener_name: external
kafka_connect_kafka_listener_name: external

kafka_broker_configure_additional_brokers: true
kafka_broker_default_listeners:
  internal:
    sasl_protocol: OAUTH
    port: 9093 #I prefer to personally have any internal trafic on non-common ports. So I change it.
  external:
    name: EXTERNAL
    port: 9092
kafka_broker_custom_listeners:
  broker:
    name: BROKER
    port: 9091

rbac_enabled: true
rbac_mds_public_key_path: "/var/ssl/private/public.pem"
rbac_mds_private_key_path: "/var/ssl/private/tokenKeypair.pem"


#START: 5.4 Only. 
# These are custom variables used below. They are not part of CP-Ansible at this time
#rbac_mds_public_key_filepath: pem/public.pem
#rbac_mds_private_key_filepath: pem/tokenKeypair.pem
#
#kafka_broker_configure_additional_brokers: true #The following 3 sets are needed to provide proper advertisment
#kafka_broker_inter_broker_listener_name: internal #Ensure we don't use the OAUTH/RBAC listener we enable
#kafka_broker_custom_listeners:
#  rbac:
#    name: RBAC
#    port: 9093
#    ssl_enabled: true
#    ssl_mutual_auth_enabled: "{{ ssl_mutual_auth_enabled }}"
#    sasl_protocol: OAUTHBEARER
#    server_callback: io.confluent.kafka.server.plugins.auth.token.TokenBearerValidatorCallbackHandler
#    login_callback: io.confluent.kafka.server.plugins.auth.token.TokenBearerServerLoginCallbackHandler
#    options:
#      publicKeyPath: "{{ rbac_mds_public_key_path }}"
#    hostname: "{{inventory_hostname}}"
#END

#START Ansible 5.5+ Only
mds_super_user: nikoleta-kfk1
mds_super_user_password: "{{vault_service_account_password}}"

kafka_broker_principal: admin #This can be defined once globally or seperatly on each brokers vars

schema_registry_ldap_user: nikoleta-kfk1
schema_registry_ldap_password: "{{vault_service_account_password}}"
kafka_connect_ldap_user: nikoleta-kfk1
kafka_connect_ldap_password: "{{vault_service_account_password}}"
ksql_ldap_user: nikoleta-kfk1
ksql_ldap_password: "{{vault_service_account_password}}"
kafka_rest_ldap_user: nikoleta-kfk1
kafka_rest_ldap_password: "{{vault_service_account_password}}"
control_center_ldap_user: nikoleta-kfk1
control_center_ldap_password: "{{vault_service_account_password}}"

create_mds_certs: false
token_services_public_pem_file: pem/public.pem
token_services_private_pem_file: pem/tokenKeypair.pem

ldap_config: "" # 5.5 Adds this var as 1 big multiline string. I think this is gross. So I define all my configs using the tradition properties route.  
#END


    
kafka_broker:
  properties:
    #MDS - RBAC Configurations
    confluent.authorizer.access.rule.providers: ZK_ACL,CONFLUENT #Enable both Centralized ZK ACLs and RBAC
    #MDS - MDS & LDAP Configs
    #Users:
    #  User:admin - This is a SCRAM user that the internal broker communications will use
    #  User:nikoleta-kfk1 & User:nikoleta-kfk2 are system account/client from LDAP that other components will use
    #  User:nikoleta is an LDAP provided user. In this case a User not a Client.
    #
    #START Ansible 5.4.x reguires you to define the super users this way
    #super.users: User:admin;User:nikoleta-kfk1;User:nikoleta-kfk2;User:nikoleta
    #broker.users: User:admin
    #confluent.metadata.server.authentication.method: BEARER
    #confluent.metadata.server.public.key.path: "{{rbac_mds_public_key_path}}"
    #confluent.metadata.server.token.key.path: "{{rbac_mds_private_key_path}}"
    #confluent.metadata.server.token.max.lifetime.ms: 3600000
    #END
    #
    #Sometimes you'll get the error "javax.naming.PartialResultException: Unprocessed Continuation Reference(s);" Changing the port can help.
    #  If you were using the port 389 change it to 3268
    #  If you were using the port 636 change it to 3269
    #  Reasoning: A GC (global catalog) server returns referrals on 389 to refer to the greater AD "forest", but acts like a regular LDAP server on 3268 (and 3269 for LDAPS)
    ldap.java.naming.provider.url: ldap://ad.bootcamp.confluent.io:3268
    ldap.java.naming.security.authentication: simple
    ldap.java.naming.security.credentials: "{{vault_service_account_password}}"
    ldap.java.naming.security.principal: "CN=Nikoleta KFK1,OU=Nikoleta,OU=BOOTCAMP,DC=ad,DC=bootcamp,DC=confluent,DC=io"
    #How to enable LDAPS (aka SSL/TLS for LDAP)
    #ldap.java.naming.security.protocol: SSL
    #ldap.ssl.truststore.location: "{{kafka_broker_truststore_path}}"
    #ldap.ssl.truststore.password: "{{kafka_broker_truststore_storepass}}"
    #Sample Group Based LDAP Search
    #ldap.group.name.attribute: sAMAccountName
    #ldap.group.object.class: group
    #ldap.group.search.base: OU=BOOTCAMP,DC=ad,DC=bootcamp,DC=confluent,DC=io
    #ldap.group.search.scope: 2
    #Sample User Based LDAP Search
    ldap.search.mode: USERS
    ldap.user.name.attribute: sAMAccountName
    ldap.user.object.class: user
    ldap.user.search.base: DC=ad,DC=bootcamp,DC=confluent,DC=io
    ldap.user.search.scope: 2
    ldap.user.memberof.attribute: memberOf
    ldap.user.memberof.attribute.pattern: "CN=(.*),OU=Nikoleta,OU=BOOTCAMP,DC=ad,DC=bootcamp,DC=confluent,DC=io"
    ldap.user.search.filter: "(memberOf=CN=NikoletaGroup,OU=Nikoleta,OU=BOOTCAMP,DC=ad,DC=bootcamp,DC=confluent,DC=io)"

control_center:
  properties:
    # Enable RBAC authorization in Control Center by providing a comma-separated list of Metadata Service (MDS) URLs
    confluent.metadata.bootstrap.server.urls: "{% for host in groups['kafka_broker'] %}{% if loop.index > 1%},{% endif %}http://{{ host }}:8090{% endfor %}"
    # MDS credentials of an RBAC user for Control Center to act on behalf of
    # NOTE: This user must be a SystemAdmin on each Apache Kafka cluster
    confluent.metadata.basic.auth.user.info: "nikoleta-kfk1:{{vault_service_account_password}}"
    # Enable authentication using a bearer token for Control Center's REST endpoints
    confluent.controlcenter.rest.authentication.method: BEARER
    # NOTE: Must match the MDS public key
    public.key.path: "{{rbac_mds_public_key_path}}"

schema_registry:
  properties:
    # These properties install the Schema Registry security plugin, and configure it to use |rbac| for
    # authorization and OAuth for authentication
    schema.registry.resource.extension.class: io.confluent.kafka.schemaregistry.security.SchemaRegistrySecurityResourceExtension
    confluent.schema.registry.authorizer.class: io.confluent.kafka.schemaregistry.security.authorizer.rbac.RbacAuthorizer
    rest.servlet.initializor.classes: io.confluent.common.security.jetty.initializer.InstallBearerOrBasicSecurityHandler
    confluent.schema.registry.auth.mechanism: JETTY_AUTH
    confluent.metadata.bootstrap.server.urls: "{% for host in groups['kafka_broker'] %}{% if loop.index > 1%},{% endif %}http://{{ host }}:8090{% endfor %}"
    # Credentials to use with the MDS, these should usually match those used for talking to Kafka
    confluent.metadata.basic.auth.user.info: "nikoleta-kfk1:{{vault_service_account_password}}"
    confluent.metadata.http.auth.credentials.provider: BASIC
    # The path to public keys that should be used to verify json web tokens during authentication
    public.key.path: "{{rbac_mds_public_key_path}}"
    # This enables anonymous access with a principal of User:ANONYMOUS
    confluent.schema.registry.anonymous.principal: "true"
    authentication.skip.paths: "/*"
    #This was needed for when not having a license key. However needs to be tested when one is provided
    kafkastore.connection.url: "{% for host in groups['zookeeper'] %}{% if loop.index > 1%},{% endif %}{{ host }}:{{zookeeper.properties.clientPort}}{% endfor %}"

kafka_connect:
  properties:
    # Adds the RBAC REST extension to the Connect worker
    rest.extension.classes: io.confluent.connect.security.ConnectSecurityExtension
    # The location of a running metadata service
    confluent.metadata.bootstrap.server.urls: "{% for host in groups['kafka_broker'] %}{% if loop.index > 1%},{% endif %}http://{{ host }}:8090{% endfor %}"
    # Credentials to use when communicating with the MDS
    confluent.metadata.basic.auth.user.info: "nikoleta-kfk1:{{vault_service_account_password}}"
    confluent.metadata.http.auth.credentials.provider: BASIC
    rest.servlet.initializor.classes: io.confluent.common.security.jetty.initializer.InstallBearerOrBasicSecurityHandler
    # The path to a directory containing public keys that should be used to verify json web tokens
    # during authentication
    public.key.path: "{{rbac_mds_public_key_path}}"
    #Allows override of producer/consumer settings via the JSON payload
    connector.client.config.override.policy: All
        